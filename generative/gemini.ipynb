{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gemini_f\n",
    "import pandas as pd\n",
    "import textwrap\n",
    "\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "import sys, os, inspect, time\n",
    "sys.path.append(\"..\")\n",
    "import config\n",
    "\n",
    "def to_markdown(text):\n",
    "  text = text.replace('â€¢', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to securely store the API key\n",
    "load_dotenv()\n",
    "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "for m in genai.list_models():\n",
    "    if 'generateContent' in m.supported_generation_methods:\n",
    "        print(m.name)\n",
    "\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "# Different prompt-techniques\n",
    "prompt_techniques = [gemini_f.general_simple, gemini_f.general_complex, gemini_f.domain_simple, gemini_f.domain_complex]\n",
    "\n",
    "# 1 for force yes or no response, 0 for not\n",
    "extra_correction = [1]\n",
    "\n",
    "# Different folder and datasets\n",
    "folders = [config.STRUCTURED_DIR, config.DIRTY_DIR, config.TEXTUAL_DIR]\n",
    "\n",
    "datasets = [config.AMAZON_GOOGLE_DIR, config.BEER_DIR, config.DBLP_ACM_DIR, \n",
    "            config.DBLP_GOOGLESCHOLAR_DIR, config.FODORS_ZAGATS_DIR, \n",
    "            config.ITUNES_AMAZON_DIR, config.WALMART_AMAZON_DIR\n",
    "]\n",
    "\n",
    "save_folder = 'llama3_predictions'\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "\n",
    "total_preds = 0\n",
    "for folder_name in folders:\n",
    "    for dataset_name in datasets:\n",
    "        try:\n",
    "            train, val, test = config.load_datasets(folder_name, dataset_name)\n",
    "            total_preds += len(test)*4\n",
    "        except:\n",
    "            print(f\"Dataset {folder_name}_{dataset_name} does not exist.\")\n",
    "            continue\n",
    "print(f\"Total predictions: {total_preds}\")\n",
    "\n",
    "llama3 = LLama3()\n",
    "for x, folder_name in enumerate(folders):\n",
    "    for y, dataset_name in enumerate(datasets):\n",
    "        try:\n",
    "            csv_name = f\"{folder_name}_{dataset_name}\"               \n",
    "\n",
    "            if not os.path.exists(f\"{save_folder}/{csv_name}.csv\"):\n",
    "                with open(f\"{save_folder}/{csv_name}.csv\", 'w') as f:\n",
    "                    f.write(\"general_or_domain,simple_or_complex,force_or_not,tableA_id,tableB_id,pred,label, time\\n\")\n",
    "\n",
    "            train, val, test = config.load_datasets(folder_name, dataset_name)\n",
    "            tableA_df, tableB_df = config.tableA_tableB(folder_name, dataset_name)\n",
    "\n",
    "            columns = tableA_df.columns\n",
    "            if 'id' in columns:\n",
    "                columns = columns.drop('id')\n",
    "\n",
    "            tableA, tableB, label = test['ltable_id'], test['rtable_id'], test['label']\n",
    "\n",
    "            for z in range(len(tableA)):\n",
    "                idA, idB, single_label = tableA.iloc[z], tableB.iloc[z], label.iloc[z]\n",
    "                rowA = tableA_df[tableA_df['id'] == idA].drop(columns='id')\n",
    "                rowB = tableB_df[tableB_df['id'] == idB].drop(columns='id')\n",
    "                sentenceA = gemini_f.format_columns_string(*columns).format(**rowA.to_dict('records')[0])\n",
    "                sentenceB = gemini_f.format_columns_string(*columns).format(**rowB.to_dict('records')[0])\n",
    "\n",
    "                for prompt in prompt_techniques:\n",
    "                    for force in extra_correction:\n",
    "                        domain = gemini_f.determine_domain(dataset_name) if prompt not in [gemini_f.general_simple, gemini_f.general_complex] else None\n",
    "                        prompt_sentence = gemini_f.generate_prompt_sentence(sentenceA, sentenceB, force, prompt, domain)\n",
    "                        \n",
    "                        start = time.time()\n",
    "                        response = llama3.llama_chat_get_response(prompt_sentence)\n",
    "                        end = time.time()\n",
    "                        time_taken = end - start\n",
    "\n",
    "                        pred = gemini_f.parse_response(response)\n",
    "                        simple_or_complex = gemini_f.determine_complexity(prompt)\n",
    "                        general_or_domain = 'domain' if prompt in [gemini_f.domain_simple, gemini_f.domain_complex] else 'general'\n",
    "                        yes_or_no = 1 if force else 0\n",
    "\n",
    "                        gemini_f.save_predictions(f\"{save_folder}/{csv_name}.csv\", general_or_domain, simple_or_complex, yes_or_no, idA, idB, pred, single_label, time_taken)\n",
    "        except:\n",
    "            print(f\"Dataset {folder_name}_{dataset_name} does not exist.\")\n",
    "            continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
